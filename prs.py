# -*- coding: utf-8 -*-
"""PRS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yGbhYTxVypgqMo-Uk4_T39Y0HS6k0HBQ

#**Product Recommendation System**

##**Project Overview**
Dalam proyek ini, kami membangun sistem rekomendasi produk, dari situs web e-commerce, menggunakan pendekatan *Content-Based Filtering* dan *Collaborative Filtering* untuk membantu pengguna menemukan produk yang relevan berdasarkan preferensi/ riwayat pembelian dan perilaku penelusuran mereka

1. Content-Based Filtering yaitu menganalisis karakteristik produk untuk memberikan rekomendasi berdasarkan kesamaan dengan produk lain.
2. Collaborative Filtering yaitu menggunakan data interaksi pengguna untuk merekomendasikan produk yang diminati oleh pengguna serupa.

##**Business Understanding**

**Problem Statements**<br>
Pengguna sering menghadapi tantangan dalam memilih produk yang tepat karena banyaknya pilihan yang ada, yang sesuai untuk kondisi mereka. Oleh karena itu, penting untuk menciptakan sistem rekomendasi yang dapat membantu pengguna dalam memilih produk yang tepat dan relevan, dimana pengguna puas, sekaligus dapat meningkatkan penjualan & profit perusahaan.

**Goals**<br>
1. Mengembangkan sistem rekomendasi produk yang dapat memberikan saran produk yang lebih tepat berdasarkan data produk, konsumen dan pengalaman pengguna lain.
2. Membantu konsumen dalam memilih produk yang lebih sesuai dan memuaskan, sekaligus meningkatkan penjualan produk dari perusahaan, dengan memanfaatkan pendekatan algoritma Content-Based Filtering dan Collaborative Filtering.

**Solution Approach**<br>
* Content-Based Filtering digunakan untuk memberikan rekomendasi item yang serupa dengan apa yang pernah dibeli atau dilihat pengguna sebelumnya berdasarkan detail karakteristik/ atribut produk, seperti kategori, merek, harga dan diskripsi produk.
* Collaborative Filtering digunakan untuk memberikan rekomendasi dari data perilaku konsumen untuk mengidentifikasi pola berdasarkan rating dan preferensi pengguna lain yang memiliki riwayat pembelian sebelumnya.

##**Data Understanding**

**Exploratory Data Analysis (EDA) & Data Visualization**<br>

Sebelum membangun model, perlu dilakukan eksplorasi data untuk memahami struktur dataset dan kualitasnya.

Dalam proyek ini, kami menggunakan dataset yang berasal dari database "Bigbasket", supermarket grosir online terbesar di India, yang dapat di akses pada link [ini](https://www.kaggle.com/datasets/amrit0611/big-basket-product-analysis/data).
"""

# Import library
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import os
import re
from sklearn.preprocessing import LabelEncoder, StandardScaler, Normalizer
from sklearn.model_selection import train_test_split
from sklearn.decomposition import TruncatedSVD
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import GridSearchCV, cross_val_score
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity, linear_kernel
from sklearn.metrics import mean_squared_error, precision_score
from sklearn.neighbors import NearestNeighbors

from google.colab import drive
drive.mount('/content/drive/')

# Load dataset
df = pd.read_csv('/content/drive/MyDrive/BigBasketProducts.csv')

"""  **1. Output 5 baris pertama dataset "BigBasketProducts.csv" dengan fungsi ```head```**"""

df.head()

"""**2. Struktur dataset**<br>
Dataset terdiri dari 10 kolom dengan 27555 baris. Mayoritas kolom bertipe ```object``` dan sebagian bertipe ```float64``` kecuali kolom *index* bertipe ```int64```. Berikut detail variabel fitur dataset ini:<br>

        index: Nama obat yang digunakan.
        product: Nama produk (dapat digunakan untuk deskripsi dalam Content-Based Filtering).
        category: Kategori utama produk.
        sub_category: Sub-kategori produk.
        brand: Merek produk.
        sale_price: Harga jual produk diplatform e-commerce.
        market_price: Harga produk dipasaran.
        type: Tipe produk (lebih spesifik dibanding kategori/sub-kategori).
        rating: Rating pengguna (berguna untuk evaluasi Collaborative Filtering).
        description: Deskripsi produk (fitur utama untuk Content-Based Filtering).
"""

df.shape

df.info()

"""**3. Statistik Deskriptif (untuk kolom Age)**:<br>
Kolom yang dapat diproses menggunakan fungsi ```describe()``` adalah kolom  bertipe numeric, yaitu data ```int64``` & ```float64```. Berdasarkan output dibawah, rentang harga jual di platform, dari terendah (```min```) adalah 2,45 Rupee hingga harga tertinggi (```max```) 12.500 Rupee, sedangkan rata-rata rating (```mean```) adalah 3,94.
"""

df.describe()

"""**4. Data Kosong (Missing Values)**<br>
Kolom *rating* memiliki nilai yang hilang yang paling tinggi (8626 nilai kosong, dari total 27555 entri), yang bisa jadi mempengaruhi analisis lebih lanjut.
"""

df.isnull().sum()

"""**5. Jumlah nilai unik setiap kolom**"""

for column in df.columns:
    print(f'{column} mempunyai {df[column].nunique()} nilai yang unik')

"""**6. Visualisasi jumlah item disetiap kategori**"""

sns.countplot(data=df, x='category')
plt.xticks(rotation=75)

"""**7. Visualisasi 10 produk terlaris**"""

top_10 = pd.DataFrame(df[['product', 'category']].value_counts().head(10)).reset_index()
top_10.columns = ['produk', 'kategori', 'jumlah']
top_10

data = df['product'].value_counts()[:10]
plt.figure(figsize=(14,7))
sns.barplot(x=data,y=data.index)
plt.xlabel('Jumlah',fontdict={'fontsize': 20})
plt.ylabel('Produk',fontdict={'fontsize': 20})
plt.title('10 Produk Terlaris',fontweight="bold",fontdict={'fontsize': 25})
plt.rcParams['font.size'] = 10

"""**8. Daftar 10 produk yang paling sedikit terjual**"""

least_10 = pd.DataFrame(df[['product', 'category']].value_counts().tail(10)).reset_index()
least_10.columns = ['produk', 'kategori', 'jumlah']
least_10

"""**9. Produk unggulan (rating 5) berbasis kategori**"""

max_rating = df['rating'].max()
top_items = df.loc[df['rating'] == max_rating]
top_items

sns.countplot(x='category', data=top_items, hue='category', palette='GnBu', order = top_items['category'].value_counts().index)
plt.xticks(rotation=75)
plt.title('Top Categories: Rating 5.0')
plt.show()

"""**10. Produk dengan rating terendah "1" berbasis kategori**"""

min_rating = df['rating'].min()
bottom_items = df.loc[df['rating'] == min_rating]
bottom_items

sns.countplot(x='category', data=bottom_items, hue='category', palette='GnBu', order = bottom_items['category'].value_counts().index)
plt.xticks(rotation=85)
plt.title('Bottom Categories: Rating 1.0')
plt.show()

"""##**Data Preparation**

**1. Dropping Uneeded Column**<br>
Kita akan menghapus kolom yang tidak relevan untuk analisis lebih lanjut.
"""

df.drop('index', axis=1, inplace=True)
df.head()

"""**2. Detection and Removal Duplicates**<br>
Sebelum membangun model, kita akan memeriksa duplikasi dalam data dan menghapusnya untuk memastikan data yang digunakan tidak redundan.
"""

print(f"Total Duplicates : {df.duplicated().sum()}")
df.drop_duplicates(inplace=True)
print(f"After remove Duplicates : {df.duplicated().sum()}")

"""**3. Handling Missing Value**<br>
Kita juga perlu menangani nilai yang hilang dalam data, baik dengan mengisi nilai yang hilang atau menghapus baris yang mengandung nilai yang hilang.
"""

# sebelum perlakuan
df.isnull().sum()

# Distribusi kolom rating
sns.histplot(df.rating,kde=True)

# Mean ratings
rating_mean = df.rating.mean()
rating_mean

# Median ratings
rating_median = df.rating.median()
rating_median

# Nilai rating yang hilang, diisi dengan nilai mean rating
df['rating'] = df['rating'].fillna(value=rating_mean)

# Prosentase nilai yang hilang keseluruan
print('Total Data Null')
null_count = df.isnull().sum().sum()
total_count = np.product(df.shape)
print("{:.2f}".format(null_count/total_count * 100))

# Menghapus nilai yang hilang
df.dropna()

# setelah perlakuan
df.reset_index(drop=True, inplace=True)
df.info()

"""**4. Changing Certain Value** (menghapus &, memisahkan string, menyusun dalam bentuk list)"""

df2 = df.copy()

rmv_spc = lambda a:a.strip()
get_list = lambda a:list(map(rmv_spc,re.split('& |, |\*|\n', a)))

for col in ['category', 'sub_category', 'type']:
    df2[col] = df2[col].apply(get_list)

"""**5. Changing Certain Value** (merubah jadi huruf kecil, menghilangkan spasi)"""

def cleaner(x):
    if isinstance(x, list):
        return [str.lower(i.replace(" ", "")) for i in x]
    else:
        if isinstance(x, str):
            return str.lower(x.replace(" ", ""))
        else:
            return ''

for col in ['category', 'sub_category', 'type','brand']:
    df2[col] = df2[col].apply(cleaner)

"""**6. Content-Based Filtering** <br>
- Menggabungkan nilai kategori, sub kategori, tipe & brand
"""

df_cbf = df2.copy()

def couple(x):
    return ' '.join(x['category']) + ' ' + ' '.join(x['sub_category']) + ' '+x['brand']+' ' +' '.join( x['type'])
df_cbf['gab'] = df_cbf.apply(couple, axis=1)

"""- Ekstraksi Fitur TF-IDF"""

tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(df_cbf['gab'])
tfidf_matrix.shape

"""**7. Collaborative Filtering**<br>
- Simulate user IDs
"""

df2['userID'] = (df2.index % 500) + 1

df2

"""- Encode Label<br>
Untuk menggunakan algoritma berbasis matriks, kita perlu mengonversi data kategorikal menjadi numerik.
"""

# Mengubah userID menjadi list tanpa nilai yang sama
user_ids = df2['userID'].unique().tolist()
print('list userID: ', user_ids)

# Melakukan encoding userID
user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userID : ', user_to_user_encoded)

# Melakukan proses encoding angka ke ke userID
user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userID: ', user_encoded_to_user)

# Mengubah product menjadi list tanpa nilai yang sama
produk_ids = df2['product'].unique().tolist()

# Melakukan proses encoding product
produk_to_produk_encoded = {x: i for i, x in enumerate(produk_ids)}

# Melakukan proses encoding angka ke product
produk_encoded_to_produk = {i: x for i, x in enumerate(produk_ids)}

# Mapping userID ke dataframe user
df2['user'] = df2['userID'].map(user_to_user_encoded)

# Mapping product ke dataframe produk
df2['produk'] = df2['product'].map(produk_to_produk_encoded)

num_users = len(user_to_user_encoded) # Mendapatkan jumlah user
num_produk = len(produk_encoded_to_produk) # Mendapatkan jumlah produk
min_rating = min(df2['rating']) # Nilai minimum rating
max_rating = max(df2['rating']) # Nilai maksimal rating

print('jumlah user: {}'.format(num_users))
print('jumlah produk: {}'.format(num_produk))
print('Min rating: {}'.format(min_rating))
print('Max rating: {}'.format(max_rating))

"""**Train Test Split**<br>
Membagi data menjadi set pelatihan dan set pengujian untuk evaluasi model.

- Split Data
"""

# Mengacak dataset
df2 = df2.sample(frac=1, random_state=42)
df2

# Membuat variabel x untuk mencocokkan data user dan produk menjadi satu value
x = df2[['user', 'produk']].values

# Membuat variabel y untuk membuat rating dari hasil
y = df2['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print("panjang array dari x_train : " + str(len(x_train)))
x_train

print("panjang array dari x_val : " + str(len(x_val)))
x_val

print("panjang array dari y_train : " + str(len(y_train)))
y_train

print("panjang array dari y_val : " + str(len(y_val)))
y_val

"""##**Modeling and Results**

**Content-Based Filtering** <br>
Menggunakan TF-IDF Vectorization dan Cosine Similarity untuk menghitung kesamaan antara produk berdasarkan atribut kategori, sub kategori, brand dan tipe produk.
"""

tfidf_matrix

cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)
cosine_sim

cosine_sim.shape

nama_produk = df_cbf['product']
produk_index = pd.Series(df_cbf.index, index=df_cbf['product'])

def product_recommendations(nama_produk, cosine_sim=cosine_sim):

    idx = produk_index[nama_produk]
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:11]
    produk_index5 = [i[0] for i in sim_scores]
    return df_cbf['product'].iloc[produk_index5]

# Nama produk yang diminta user
nama_produk_test = np.random.choice(nama_produk)
nama_produk_test

# Hasil rekomendasi produk yang relevan
rekom = product_recommendations(nama_produk_test)
pd.DataFrame({'Produk diminta': nama_produk_test,'Rekomendasi produk relevan':rekom})

"""**Collaborative Filtering**<br>
Menggunakan class RecommenderNet untuk Collaborative Filtering.
"""

!pip install tensorflow
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_produk, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_produk = num_produk
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.produk_embedding = layers.Embedding( # layer embeddings produk
        num_produk,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.produk_bias = layers.Embedding(num_produk, 1) # layer embedding produk bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    produk_vector = self.produk_embedding(inputs[:, 1]) # memanggil layer embedding 3
    produk_bias = self.produk_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_produk = tf.tensordot(user_vector, produk_vector, 2)

    x = dot_user_produk + user_bias + produk_bias

    return tf.nn.sigmoid(x) # activation sigmoid

"""**Inisialisasi model dan compile**"""

# inisialisasi model
model = RecommenderNet(num_users, num_produk, 50)

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""**Training terhadap model**"""

# callbacks
from tensorflow.keras.callbacks import EarlyStopping
early_stopper = EarlyStopping(monitor='val_root_mean_squared_error',
                              patience=10,
                              verbose=1,
                              restore_best_weights=True)

# Memulai training
history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 8,
    epochs = 100,
    callbacks = [early_stopper],
    validation_data = (x_val, y_val)
)

"""**Membuat variabel produk_not_rated sebagai daftar produk untuk direkomendasikan pada pengguna.**"""

#Mengambil sample user
user_id = df2.userID.sample(1).iloc[0]
produk_rated_by_user = df2[df2.userID == user_id]

produk_not_rated = df2[~df2['product'].isin(produk_rated_by_user.produk.values)]['product']
produk_not_rated = list(
    set(produk_not_rated)
    .intersection(set(produk_to_produk_encoded.keys()))
)

produk_not_rated = [[produk_to_produk_encoded.get(x)] for x in produk_not_rated]
user_encoder = user_to_user_encoded.get(user_id)
user_produk_array = np.hstack(
    ([[user_encoder]] * len(produk_not_rated), produk_not_rated)
)

"""**Hasil rekomendasi produk**"""

ratings = model.predict(user_produk_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_produk_ids = [
    produk_encoded_to_produk.get(produk_not_rated[x][0]) for x in top_ratings_indices
]

print('Daftar recommendations produk untuk users: {}'.format(user_id))
print('===' * 9)
print('produk dengan rating tinggi dari user')
print('----' * 8)

top_produk_user = (
    produk_rated_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    ['product'].values
)

df2_rows = df2[df2['product'].isin(top_produk_user)]
for row in df2_rows.itertuples():
    print(row.product, ':', row.brand)

print('----' * 8)
print('Top 10 produk recommendation')
print('----' * 8)

recommended_produk = df2[df2['product'].isin(recommended_produk_ids)].drop_duplicates(subset='product')
for row in recommended_produk.itertuples():
    print(row.product, ':', row.brand)

"""##**Evaluation**<br>
Untuk mengevaluasi kedua model rekomendasi ini, kita dapat menggunakan precision dan recall untuk mengukur akurasi prediksi.

###**Content Based Filtering**
"""

def evaluate_precision(nama_produk_test, rekom, df_cbf):
    """
    Fungsi untuk mengevaluasi precision rekomendasi.

    Parameters:
        nama_produk_test (str): Produk yang diminta.
        rekom (list): Produk rekomendasi yang dihasilkan.
        df_cbf (pd.DataFrame): DataFrame dengan informasi relevansi.

    Returns:
        float: Nilai precision untuk produk yang diuji.
    """

    # Mendapatkan relevansi produk rekomendasi
    df_cbf['relevant'] = df_cbf['product'].isin(rekom).astype(int)

    # Filter df_cbf untuk hanya menyertakan produk yang direkomendasikan
    relevant_products_df = df_cbf[df_cbf['product'].isin(rekom)]

    # Nilai target sebenarnya (relevansi) untuk produk yang direkomendasikan
    y_true = relevant_products_df['relevant'].values
    y_pred = [1] * len(y_true)

    # Hitung precision (menangani zero division jika diperlukan)
    precision = precision_score(y_true, y_pred, zero_division=0)
    return precision

# Evaluasi model menggunakan precision
precision_value = evaluate_precision(nama_produk_test, rekom, df_cbf)
print(f"Precision untuk produk '{nama_produk_test}': {precision_value:.2f}")

"""###**Collaborative Filtering**"""

# Menampilkan grafik traning vs test
plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""###**References**

# Ali Saifudin (drh_ali)

ali.saifudin.385758-2022@fkh.unair.ac.id

Kabupaten Blora
'''
"""